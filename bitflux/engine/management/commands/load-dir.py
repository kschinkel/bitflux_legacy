from django.core.management.base import BaseCommand, CommandErrorfrom bitflux.engine.models import autoDLEntryfrom bitflux.engine.models import Jobfrom bitflux.engine.models import UserProfilefrom bitflux.engine.models import deamonfrom bitflux.engine.models import autoDLerfrom bitflux.engine.models import autoDLEntryfrom bitflux.engine.models import logfrom bitflux.engine.management.commands import commonfrom django.conf import settingsimport subprocess import timeimport datetimeimport osimport sysimport ctypesimport timeimport signalfrom datetime import timedeltaimport reimport threading,threadimport httplibimport urllibimport xmlrpclibimport random, stringimport tracebacktry:    import jsonexcept ImportError:    import simplejson as jsonfrom HTMLParser import HTMLParserdef log_to_file(msg):    f = open("load-dir.log", 'a')    f.write(str(datetime.datetime.now())+": "+msg+"\n")    f.close    def loadDirectory(full_url, local_directory, status, autorename):    #autorename = bool(autorename)    myparser  = common.MyHTMLParser()    myparser.set_parent_info(full_url, local_directory, status, autorename)        #continue to parse directory for entries    m = re.match(r"(?P<type>[^:]+)://(?P<host>[^:/]+)(:(?P<port>\d+))?(?P<path>.*)", full_url)    mvals = m.groupdict()    if mvals['port'] is None:        mvals['port'] = 80        if mvals['type'] == 'https':            mvals['port'] = 443    basic_auth = settings.USERNAME + ":"+settings.PASSWORD    encoded = basic_auth.encode("base64")[:-1]    headers = {"Authorization":"Basic %s" % encoded}    params = ""    try:        if mvals['type'] == 'https':            conn = httplib.HTTPSConnection(mvals['host'],mvals['port'], timeout=10)        else:            conn = httplib.HTTPConnection(mvals['host'],mvals['port'], timeout=10)        conn.request('GET',mvals['path'],params,headers);        responce = conn.getresponse()        fullhtmlpage = responce.read()        conn.close()        myparser.feed(fullhtmlpage)    except Exception,e:        log_to_file("Failed to load directory: " + full_url)        return    for entry in myparser.set_links_with_dir(full_url):        OUT_list = entry.split('/')        filename = OUT_list.pop()        filename = urllib.unquote(filename)        log_to_file("Entry in directory found:" + filename)                try:            responce, filename, size = common.getEntryInfo(entry)        except:            size = -1        out_list = mvals['path'].split('/')        dir = out_list.pop()        dir = out_list.pop()        dir = urllib.unquote(dir)        entry = urllib.unquote(entry)        m = re.match(r"(?P<type>[^:]+)://(?P<host>[^:/]+)(:(?P<port>\d+))?(?P<path>.*)", entry)        mvals = m.groupdict()        full_dl_path = mvals['type']+'://' + mvals['host'] + urllib.quote(mvals['path'] )                #out = profile.dl_dir+filename        try:            Job.objects.lock()             new_job = Job()                        if autorename == "True":                #Add renamer code here                new_job.autorename = True                '''show_name = common.is_tv_show(filename)                if len(show_name) > 0:                    filename = show_name            else:                new_job.autorename = False            if status.endswith('Queue'):                status = 'Queued'            elif status.endswith('Stop'):                status = 'Stopped'            elif status.endswith('Start'):                status = 'Starting...'''                        #filename = unicode(filename, errors='ignore')            new_job.status = status            new_job.queue_id = len(Job.objects.all())            new_job.gid = -1            new_job.process_pid = -1            new_job.dl_speed = 0            new_job.time_seg_start = -1            new_job.time_seg_end = -1            new_job.display_size = common.convert_bytes(size)            new_job.total_size = size            new_job.dled_size = 0            #new_job.dled_dif_size = 0; removed            new_job.full_url = full_dl_path            new_job.local_directory = local_directory            new_job.filename = common.name_wrapper(filename)            new_job.notes = "CURL download: " + new_job.local_directory + new_job.filename            new_job.progress = 0;            new_job.eta = "";            new_job.save()        finally:            Job.objects.unlock()    myparser.close()    class Command(BaseCommand):    def handle(self, *args, **options):        if len(args) != 4:            log_to_file("invalid number of arguments!")            exit(-1)        log_to_file("parsing directory: " + args[0])        loadDirectory(args[0], args[1], args[2], args[3])